import os, re, json, pymysql, torch, whisper, dateparser
from datetime import datetime, timedelta
from typing import List, Optional
from pydantic import BaseModel
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from prompts.meeting_summary_prompt import meeting_summary_prompt

# ===================== ì„¤ì • =====================
from dotenv import load_dotenv
import os

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

DB_HOST, DB_USER, DB_PASSWORD, DB_NAME, DB_PORT = (
    "112.175.29.231", "cheolwoo", "1234", "meeting_summary2", 33067
)

# ===================== Pydantic êµ¬ì¡° =====================
class ActionItem(BaseModel):
    name: str
    task: str
    due: Optional[str]

class MeetingSummary(BaseModel):
    topic_summary: str
    content_summary: str
    decisions: List[str]
    action_items: List[ActionItem]


# ===================== ë‚ ì§œ ì •ê·œí™” í•¨ìˆ˜ (ê°•í™” + ì—°ë„ ë³´ì •) =====================
def normalize_due(due_text: Optional[str], base_dt: datetime) -> Optional[str]:
    """LLMì´ ë°˜í™˜í•œ due ë¬¸ìì—´ì„ ë¬¸ë§¥ê¸°ë°˜ ì‹¤ì œ ë‚ ì§œë¡œ ë³€í™˜"""
    if not due_text:
        return None
    s = str(due_text).strip()
    if s in {"ë¯¸ì •", "ë¶ˆëª…", "null", "ì—†ìŒ", ""}:
        return None
    if s in {"ì˜¤ëŠ˜", "ì˜¤ëŠ˜ ì¤‘"}:
        return base_dt.strftime("%Y-%m-%d")
    if s.startswith("ë‚´ì¼"):
        return (base_dt + timedelta(days=1)).strftime("%Y-%m-%d")
    if s.startswith("ëª¨ë ˆ"):
        return (base_dt + timedelta(days=2)).strftime("%Y-%m-%d")

    # ì§ì ‘ YYYY-MM-DD í˜•ì‹ì¸ ê²½ìš°
    if re.match(r"\d{4}-\d{2}-\d{2}", s):
        # ğŸ”¹ ê³¼ê±° ì—°ë„ë©´ ìë™ìœ¼ë¡œ ì˜¬í•´ë¡œ êµì²´
        y, m, d = map(int, s.split("-"))
        if y < base_dt.year:
            s = f"{base_dt.year}-{m:02d}-{d:02d}"
        return s

    # ì´ë²ˆì£¼ / ë‹¤ìŒì£¼ íŒ¨í„´
    week_map = {
        "ì´ë²ˆì£¼ ì›”ìš”ì¼": 0, "ì´ë²ˆì£¼ í™”ìš”ì¼": 1, "ì´ë²ˆì£¼ ìˆ˜ìš”ì¼": 2,
        "ì´ë²ˆì£¼ ëª©ìš”ì¼": 3, "ì´ë²ˆì£¼ ê¸ˆìš”ì¼": 4,
        "ë‹¤ìŒì£¼ ì›”ìš”ì¼": 7, "ë‹¤ìŒì£¼ í™”ìš”ì¼": 8, "ë‹¤ìŒì£¼ ìˆ˜ìš”ì¼": 9,
        "ë‹¤ìŒì£¼ ëª©ìš”ì¼": 10, "ë‹¤ìŒì£¼ ê¸ˆìš”ì¼": 11,
    }
    for k, d in week_map.items():
        if k in s:
            return (base_dt + timedelta(days=d)).strftime("%Y-%m-%d")

    # ì¼ë°˜ ìì—°ì–´ ë‚ ì§œ íŒŒì‹± (ì—°ë„ ë³´ì •)
    parsed = dateparser.parse(
        s,
        languages=["ko"],
        settings={
            "RELATIVE_BASE": base_dt,
            "PREFER_DATES_FROM": "future"  # âœ… ë¯¸ë˜ ë‚ ì§œ ìš°ì„ 
        },
    )
    if parsed:
        # ğŸ”¹ ì—°ë„ ë³´ì •: ê³¼ê±° ì—°ë„ë©´ ì˜¬í•´ë¡œ ë®ì–´ì“°ê¸°
        if parsed.year < base_dt.year:
            parsed = parsed.replace(year=base_dt.year)
        return parsed.strftime("%Y-%m-%d")

    return None


# ===================== ì•ˆì „í•œ JSON íŒŒì‹± =====================
def safe_llm_json(llm, prompt_text, retries=2):
    for i in range(retries + 1):
        resp = llm.invoke(prompt_text)
        text = resp.content.strip()
        json_part = re.search(r'\{[\s\S]*\}', text)
        if not json_part:
            continue
        try:
            return json.loads(json_part.group(0))
        except json.JSONDecodeError:
            prompt_text += "\n\nJSON í˜•ì‹ë§Œ ì •í™•íˆ ì¶œë ¥í•´ì£¼ì„¸ìš”."
    raise ValueError("âŒ LLMì´ ì˜¬ë°”ë¥¸ JSONì„ ë°˜í™˜í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

# ===================== íšŒì˜ ì¼ì ì¶”ì • í”„ë¡¬í”„íŠ¸ =====================
meeting_date_prompt = PromptTemplate.from_template("""
ë‹¤ìŒ íšŒì˜ ëŒ€í™” ë‚´ìš©ì„ ë³´ê³  íšŒì˜ê°€ ì‹¤ì œë¡œ ì—´ë¦° ë‚ ì§œë¥¼ ì¶”ì •í•˜ì„¸ìš”.
ìƒëŒ€ì  í‘œí˜„(ì˜¤ëŠ˜, ë‚´ì¼, ì´ë²ˆ ì£¼, ë‹¤ìŒ ì£¼ ë“±)ì„ ê³ ë ¤í•˜ì—¬ ISO í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.

ì¶œë ¥ ì˜ˆì‹œ:
{{ "meeting_date": "2025-10-27" }}

íšŒì˜ë¡:
{text}
""")

# ===================== í•µì‹¬ íŒŒì´í”„ë¼ì¸ =====================
def run_meeting_pipeline(audio_path: str) -> dict:
    if not os.path.exists(audio_path):
        raise FileNotFoundError(f"âŒ íŒŒì¼ ì—†ìŒ: {audio_path}")

    # === 1ï¸âƒ£ Whisper STT ë³€í™˜ ===
    model = whisper.load_model("small")
    print(f"ğŸ™ï¸ Whisper ë³€í™˜ ì¤‘... {audio_path}")
    result = model.transcribe(audio_path, language="ko")
    full_text = result["text"].strip()

    # === 2ï¸âƒ£ íšŒì˜ì¼ì ì¶”ì • ===
    llm_date = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)
    try:
        date_json = safe_llm_json(llm_date, meeting_date_prompt.format(text=full_text))
        base_dt = dateparser.parse(date_json.get("meeting_date", ""), languages=["ko"]) or datetime.now()

        # ğŸ”§ ì—°ë„ ë³´ì • (LLMì´ ê³¼ê±° ì—°ë„ ì¶”ì •í•  ê²½ìš°)
        if base_dt.year < datetime.now().year:
            base_dt = base_dt.replace(year=datetime.now().year)

    except Exception:
        base_dt = datetime.now()


    # === 3ï¸âƒ£ íšŒì˜ ìš”ì•½ / ê²°ì •ì‚¬í•­ / ì•¡ì…˜ì•„ì´í…œ ì¶”ì¶œ ===
    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.2)
    prompt_text = meeting_summary_prompt.format(text=full_text)
    parsed_json = safe_llm_json(llm, prompt_text)

    # === 4ï¸âƒ£ due ë‚ ì§œ ì •ê·œí™” (ë¬¸ë§¥ ê¸°ë°˜ ë³€í™˜) ===
    for item in parsed_json.get("action_items", []):
        item["due"] = normalize_due(item.get("due"), base_dt)

    # === 5ï¸âƒ£ fallback: dueê°€ ì „ë¶€ Noneì´ë©´ ìˆœì°¨ ë°°ì • ===
    for idx, item in enumerate(parsed_json.get("action_items", [])):
        if not item.get("due"):
            item["due"] = (base_dt + timedelta(days=idx)).strftime("%Y-%m-%d")

    # === 6ï¸âƒ£ Pydantic ê²€ì¦ ===
    validated = MeetingSummary(**parsed_json)

        # === 7ï¸âƒ£ DB ì €ì¥ (ë‚´ DB + íŒ€ì› DB) ===
    try:
        # âœ… ê¸°ì¡´ ê°œì¸ DB (ì™¸ë¶€ ì„œë²„)
        conn1 = pymysql.connect(
            host=DB_HOST, user=DB_USER, password=DB_PASSWORD,
            database=DB_NAME, port=DB_PORT, charset="utf8mb4"
        )
        cur1 = conn1.cursor()
        cur1.execute("""
        INSERT INTO meeting_summary (meeting_file, topic_summary, content_summary, decisions, action_items)
        VALUES (%s,%s,%s,%s,%s)
        ON DUPLICATE KEY UPDATE
            topic_summary=VALUES(topic_summary),
            content_summary=VALUES(content_summary),
            decisions=VALUES(decisions),
            action_items=VALUES(action_items),
            created_at=CURRENT_TIMESTAMP;
        """, (
            audio_path,
            validated.topic_summary,
            validated.content_summary,
            json.dumps(validated.decisions, ensure_ascii=False),
            json.dumps([a.dict() for a in validated.action_items], ensure_ascii=False)
        ))
        conn1.commit()
        print("âœ… ê°œì¸ DB ì €ì¥ ì™„ë£Œ")

    except Exception as e:
        print("âŒ ê°œì¸ DB ì˜¤ë¥˜:", e)
    finally:
        conn1.close()

    # === ğŸ§© íŒ€ì› DBì—ë„ ì¶”ê°€ ì €ì¥ ===
    DB_CONFIG = {
        'host': 'localhost',
        'user': 'admin',
        'password': '1qazZAQ!',
        'db': 'final',
        'charset': 'utf8mb4'
    }

    try:
        conn2 = pymysql.connect(**DB_CONFIG)
        cur2 = conn2.cursor()

        # âš™ï¸ í…Œì´ë¸” ìë™ ìƒì„± (ì—†ì„ ì‹œ)
        cur2.execute("""
        CREATE TABLE IF NOT EXISTS team_meeting_summary (
            id INT AUTO_INCREMENT PRIMARY KEY,
            meeting_file VARCHAR(255) UNIQUE,
            topic_summary TEXT,
            content_summary TEXT,
            decisions JSON,
            action_items JSON,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        ) CHARACTER SET utf8mb4;
        """)

        # ğŸ’¾ ë°ì´í„° ì‚½ì… (ì¤‘ë³µ ë°©ì§€)
        cur2.execute("""
        INSERT INTO team_meeting_summary (meeting_file, topic_summary, content_summary, decisions, action_items)
        VALUES (%s,%s,%s,%s,%s)
        ON DUPLICATE KEY UPDATE
            topic_summary=VALUES(topic_summary),
            content_summary=VALUES(content_summary),
            decisions=VALUES(decisions),
            action_items=VALUES(action_items),
            created_at=CURRENT_TIMESTAMP;
        """, (
            audio_path,
            validated.topic_summary,
            validated.content_summary,
            json.dumps(validated.decisions, ensure_ascii=False),
            json.dumps([a.dict() for a in validated.action_items], ensure_ascii=False)
        ))
        conn2.commit()
        print("âœ… íŒ€ì› DB ì €ì¥ ì™„ë£Œ")

    except Exception as e:
        print("âŒ íŒ€ì› DB ì˜¤ë¥˜:", e)
    finally:
        conn2.close()

    # === 9ï¸âƒ£ DOCX íŒŒì¼ ìë™ ìƒì„± ===
    from docx import Document
    from docx.enum.text import WD_ALIGN_PARAGRAPH
    from docx.shared import Pt
    from docx.oxml.ns import qn   # âœ… ì´ ì¤„ ì¶”ê°€


    doc_dir = "static/docs"
    os.makedirs(doc_dir, exist_ok=True)
    base_filename = os.path.splitext(os.path.basename(audio_path))[0]  # í™•ì¥ì ì œê±°
    doc_path = os.path.join(
        doc_dir,
        f"íšŒì˜ë¡_{base_dt.strftime('%Y-%m-%d')}_{base_filename}.docx"
    )

    doc = Document()
    # ìŠ¤íƒ€ì¼ ì§€ì •
    style = doc.styles['Normal']
    style.font.name = 'Malgun Gothic'  # ğŸ”¹ ìœˆë„ìš°ì—ì„œ ì¡´ì¬í•˜ëŠ” í•œê¸€ í°íŠ¸
    style._element.rPr.rFonts.set(qn('w:eastAsia'), 'Malgun Gothic')
    style.font.size = Pt(12)

    # --- ì œëª© ---
    title = doc.add_heading("íšŒì˜ ìš”ì•½ ë³´ê³ ì„œ", level=1)
    title.alignment = WD_ALIGN_PARAGRAPH.CENTER

    # --- ê¸°ë³¸ ì •ë³´ ---
    doc.add_paragraph(f"ğŸ“… íšŒì˜ì¼ì: {base_dt.strftime('%Y-%m-%d')}")
    doc.add_paragraph(f"ğŸ§ íŒŒì¼ëª…: {base_filename}")
    doc.add_paragraph("")

    # --- ì£¼ì œ ìš”ì•½ ---
    doc.add_heading("1. ì£¼ì œ ìš”ì•½", level=2)
    doc.add_paragraph(validated.topic_summary)

    # --- ë‚´ìš© ìš”ì•½ ---
    doc.add_heading("2. ë‚´ìš© ìš”ì•½", level=2)
    doc.add_paragraph(validated.content_summary)

    # --- ê²°ì •ì‚¬í•­ ---
    doc.add_heading("3. ê²°ì •ì‚¬í•­", level=2)
    for d in validated.decisions:
        doc.add_paragraph(f"â€¢ {d}", style="List Bullet")

    # --- ì•¡ì…˜ ì•„ì´í…œ ---
    doc.add_heading("4. ì•¡ì…˜ ì•„ì´í…œ", level=2)
    for item in validated.action_items:
        p = doc.add_paragraph(style="List Number")
        p.add_run(f"ë‹´ë‹¹ì: {item.name}\n").bold = True
        p.add_run(f"ì‘ì—…ë‚´ìš©: {item.task}\n")
        p.add_run(f"ê¸°í•œ: {item.due if item.due else 'ë¯¸ì •'}")
        
        # === 8ï¸âƒ£ JSON íŒŒì¼ë„ ìë™ ì €ì¥ (í”„ë¡ íŠ¸ì—ì„œ ë³´ê¸°ìš©) ===
    json_dir = "static/data"
    os.makedirs(json_dir, exist_ok=True)
    json_path = os.path.join(json_dir, f"{base_filename}.json")

    with open(json_path, "w", encoding="utf-8") as f:
        json.dump({
            "topic_summary": validated.topic_summary,
            "content_summary": validated.content_summary,
            "decisions": validated.decisions,
            "action_items": [a.dict() for a in validated.action_items],
        }, f, ensure_ascii=False, indent=2)

    print(f"ğŸ“„ JSON ì €ì¥ ì™„ë£Œ: {json_path}")

    doc.save(doc_path)
    print(f"ğŸ“ DOCX ì €ì¥ ì™„ë£Œ: {doc_path}")
     # === 10ï¸âƒ£ ê²°ê³¼ ë°˜í™˜ ===
    return {
        "topic_summary": validated.topic_summary,
        "content_summary": validated.content_summary,
        "decisions": validated.decisions,
        "action_items": [a.dict() for a in validated.action_items],
        "docx_path": doc_path
    }

